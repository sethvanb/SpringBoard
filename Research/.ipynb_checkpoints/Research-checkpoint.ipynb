{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to Similar Projects\n",
    "* https://github.com/kylejohnson363/Predicting-MLB-Games-with-Machine-Learning\n",
    "* https://towardsdatascience.com/a-machine-learning-algorithm-for-predicting-outcomes-of-mlb-games-fa17710f3c04\n",
    "* https://www.researchgate.net/publication/351597865_Use_of_Machine_Learning_and_Deep_Learning_to_Predict_the_Outcomes_of_Major_League_Baseball_Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Replicating Models/Results of https://github.com/kylejohnson363/Predicting-MLB-Games-with-Machine-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/SethVanB/opt/miniconda3/lib/python3.9/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy in /Users/SethVanB/opt/miniconda3/lib/python3.9/site-packages (from xgboost) (1.20.2)\n",
      "Requirement already satisfied: scipy in /Users/SethVanB/opt/miniconda3/lib/python3.9/site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in /Users/SethVanB/opt/miniconda3/lib/python3.9/site-packages (from xgboost) (1.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nj/phxsysz17vgd3mgmzd521ft00000gn/T/ipykernel_40891/733138427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "pickle_in=open(\"cleaned_data.pickle\",\"rb\")\n",
    "df=pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a476c617844b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "pickle_in=open(\"cleaned_data.pickle\",\"rb\")\n",
    "df=pickle.load(pickle_in)\n",
    "# I need to drop two columns that I left in for the visualization notebook\n",
    "df.drop(['home_score','away_score'],axis=1,inplace=True)\n",
    "# This is the same function from the previous notebook and it will be used to\n",
    "# evaluate model performance\n",
    "def calc_return(X_analyse):\n",
    "    total_risk=[]\n",
    "    total_reward=[]\n",
    "    equal_bet_return=[]\n",
    "    for i in range(len(X_analyse)):\n",
    "        k=pd.DataFrame(X_analyse.iloc[i]).transpose()\n",
    "        k.reset_index(drop=True,inplace=True)\n",
    "        if int(k.preds[0])==1:\n",
    "            if int(k.real[0])==1:\n",
    "                if int(k.home_money[0])<0:\n",
    "                    risk=k.home_money[0]\n",
    "                    reward=100\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=k.home_money[0]\n",
    "            else:\n",
    "                if k.home_money[0]<0:\n",
    "                    risk=k.home_money[0]\n",
    "                    reward=k.home_money[0]\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=-100\n",
    "        else:\n",
    "            if int(k.real[0])==0:\n",
    "                if k.away_money[0]<0:\n",
    "                    risk=k.away_money[0]\n",
    "                    reward=100\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=k.away_money[0]\n",
    "            else:\n",
    "                if k.away_money[0]<0:\n",
    "                    risk=k.away_money[0]\n",
    "                    reward=k.away_money[0]\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=-100\n",
    "        total_risk.append(risk)\n",
    "        total_reward.append(reward)\n",
    "        equal_bet_winnings=reward/-risk*100\n",
    "        equal_bet_return.append(equal_bet_winnings)\n",
    "    natural_ror=round(-np.mean(total_reward)/np.mean(total_risk)*100,2)\n",
    "    equal_bet_ror=round(np.mean(equal_bet_return),2)\n",
    "    return natural_ror,equal_bet_ror\n",
    "# This is a function for creating train-test splits that will work with my way of\n",
    "# scoring model performance based on real world return on risk\n",
    "def test_split(data,test_size,random_state):\n",
    "    shuf_df=data.sample(frac=1,random_state=random_state)\n",
    "    shuf_df.reset_index(drop=True,inplace=True)\n",
    "    df2=shuf_df.copy()\n",
    "    # This seperates the dataframe into data and target \n",
    "    X_temp=df2[df2.columns[1:]]\n",
    "    y=df2.home_win\n",
    "    # This standardized the data\n",
    "    scaler=StandardScaler()\n",
    "    X_s = scaler.fit_transform(X_temp)\n",
    "    X=pd.DataFrame(X_s)\n",
    "    # This does the train-test split in a way that I can carry through the odds values in order to calculate\n",
    "    # the real-world usefulness of the model\n",
    "    if len(X)==len(y):\n",
    "        split_value=int(round(len(X)*(1-test_size),0))\n",
    "        X_train=X.iloc[0:split_value]\n",
    "        X_test=X.iloc[split_value:len(X)]\n",
    "        y_train=y.iloc[0:split_value]\n",
    "        y_test=y.iloc[split_value:len(X)]\n",
    "        home_money=shuf_df.iloc[:,-2]\n",
    "        away_money=shuf_df.iloc[:,-1]\n",
    "    return X_train,X_test,y_train,y_test,home_money,away_money,split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_svm_xg=pd.DataFrame([])\n",
    "for j in range(0,50):\n",
    "    X_train,X_test,y_train,y_test,home_money,away_money,split_value=test_split(df,.1,j*3)\n",
    "    svm_clf=svm.SVC(C=6,kernel='linear',random_state=j*3)\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    svm_pred=svm_clf.predict(X_test)\n",
    "    boost=xgb.XGBClassifier(learning_rate=.001,max_depth=50,\n",
    "                            min_child_weight=10,n_estimators=200,subsample=.4,gamma=10,random_state=j*3)\n",
    "    boost.fit(X_train,y_train)\n",
    "    boost_pred=boost.predict(X_test)\n",
    "    bets=pd.DataFrame([])\n",
    "    for i in range(len(y_test)):\n",
    "        if svm_pred[i]+boost_pred[i]==2:\n",
    "            bets=bets.append(pd.DataFrame({'preds':1,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "        else:\n",
    "            None\n",
    "        if svm_pred[i]+boost_pred[i]==0:\n",
    "            bets=bets.append(pd.DataFrame({'preds':0,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "    svm_acc=round(accuracy_score(y_test,svm_pred)*100,1)\n",
    "    boost_acc=round(accuracy_score(y_test,boost_pred)*100,1)\n",
    "    combo_acc=round(accuracy_score(bets.real,bets.preds)*100,1)\n",
    "    nat,equal=calc_return(bets)\n",
    "    results_svm_xg=results_svm_xg.append(pd.DataFrame({'fold':j+1,'svm_acc':svm_acc,\n",
    "                                                       'boost_acc':boost_acc,'combo_acc':combo_acc,\n",
    "                                                       'nat':nat,'equal':equal},index=[0]),ignore_index=True)\n",
    "print('Average SVM Accuracy Score: ',round(results_svm_xg.svm_acc.mean(),2))\n",
    "print('Average XG Boost Accuracy Score: ',round(results_svm_xg.boost_acc.mean(),2))\n",
    "print('Average Combined Accuracy Score: ',round(results_svm_xg.combo_acc.mean(),2))\n",
    "print('Average Natural Wager Return on Risk: ',round(results_svm_xg.nat.mean(),2))\n",
    "print('Average Equal Wager Return on Risk: ',round(results_svm_xg.equal.mean(),2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
